# Facial Recognition Technologies

- **[The Dazzle Club](https://www.instagram.com/thedazzleclub/?hl=en)**
    - **Creator:** Four Artists in London
    - **Problem:** How to prevent security cameras using facial recognition from finding them
    - **Proposed Solution:** Painting their faces with different shapes and colors to reverse how the camera reads a face
    - **Benefits:**
      - Prevent themselves from being tracked
      - Bonding experience through the group/community they’ve built during the pandemic
    - **Limitations:** 
      - Requires a lot of prep + Designing your face each day
      - May not be appropriate for certain situations + long term
      - Has a “cool/trendy” factor instead of a “practical” factor
    - **More Information** 
      - [Press](https://www.codastory.com/authoritarian-tech/london-facial-recognition-facepaint/) 

- **[Clothing that confuses facial recognition technology.](https://www.businessinsider.com/clothes-accessories-that-outsmart-facial-recognition-tech-2019-10#blas-masks-also-explore-the-potential-of-algorithm-driven-facial-recognition-to-enact-bias-and-produce-false-positives-13)**
    - **Creator:** No specific creator, just different clothes designers
    - **Problem:** How to prevent cameras from using facial recognition to identify people
    - **Proposed Solution:** The clothing is meant to "Dazzle" facial recognition software with misleading shapes that prohibit the software from knowing what it is looking at
    - **Benefits:**
        -  Works against a lot of facial recognition technology
    - **Limitations:**
        - Niche market, unlikely to become mainstream especially because the clothing is impractical (ugly).
        - Algorithms are already being developed to overcome the clothing  
    - **More Information:** https://www.businessinsider.com/clothes-accessories-that-outsmart-facial-recognition-tech-2019-10#blas-masks-also-explore-the-potential-of-algorithm-driven-facial-recognition-to-enact-bias-and-produce-false-positives-13 

- **[Fawkes](http://sandlab.cs.uchicago.edu/fawkes/)**
  - **Creator:** UChicago SAND (Security, Algorithms, Networks, and Data) Lab
  - **Problem:** Companies,Law Enforcement Agencies, etc. can search for your face across the internet through one-to-many identification (ex. police searching for criminal suspects using security-camera footage and a mug-shot database). Therefore, posts on social media or other places of your face could be identified extremely easily with facial recognition software that companies like Clearview AI have already developed. This web-scraping can also increase the accuracy of facial recognition tech to be used by law enforcement, for example, because they can create larger datasets to train the algorithms on. 
  - **Proposed Solution:** Fawkes converts an image — or “cloaks” it, in the researchers’ parlance — by subtly altering some of the features that facial recognition systems depend on when they construct a person’s face print. The software is designed to match you with the face template of someone who looks as much unlike you as possible, pulling from a database of celebrity faces. The goal is to more broadly significantly decrease the efficiency of facial recognition technologies like the one Clearview AI created by creating billions of cloaked photos on the internet that are unidentifiable.
  - **Benefits:**
    -  It can effectively make you undetectable to facial recognition softwares, and still allow you to post on the internet. It can also help to wear down the efficacy of existing web-scraping, facial recognition software over time.
  - **Limitations:**
    - Fawkes recreates AI's misidentification problem. If law enforcement runs a cloaked image through a facial recognition search, someone else will appear as a result. Thus, some uninvolved person may be subject to police arrest, interrogation or worse. 
    - It is not accessible to non-coders at the moment -- you can use the software but have to do some coding and download it to your computer. 
    - Also, some say there are already too many existing uncloaked photos on the internet, so the technology would be ineffective. However, if companies were mandated to cloak all of the photos on their sites, significant amounts of photos would be protected. This technology is not helpful at protecting you from your face being recorded in person, pre-web scraping, however. But hopefully this technology can make their algorithms fail. 
  - **More Information:**
    - [Website](http://sandlab.cs.uchicago.edu/fawkes/)


- **[Atlas of Surveillance](https://atlasofsurveillance.org)**
  - **Creator:** the Electronic Frontier Foundation and the Reynolds School of Journalism at the University of Nevada, Reno
  - **Problem:** Want a way to track and aggregate law enforcement tools of surviellance
  - **Proposed Solution:** combine crowdsourcing and data journalism to create the largest-ever repository of information on which law enforcement agencies are using what surveillance technologies
  - **Benefits**
    -  is open source so allows anyone to contribute or to learn how surveillance technology is spreading
    -  is searchable for specific technology information
  - **Limitations:**
    - Tool of data science, struggles for action
    - very reliant on volunteer research
  - **More Information:**
    - https://www.eff.org/deeplinks/2021/12/atlas-surveillance-turns-dragnet-police-tech-2021-year-review, Dave Maass


## Problematic Technologies

- **[Interpol Facial Recognition](https://www.interpol.int/en/How-we-work/Forensics/Facial-Recognition)**
  - **Creator:** Interpol
  - **Problem:** Identifying “persons of interest” at international borders; persons of interest being terrorists, criminals, fugitives, or missing persons. 
  - **Proposed Solution:** “Coupled with an automated biometric software app, this system is capable of identifying or verifying a person by comparing and analyzing patterns, shapes and proportions of their facial features and contours.”  They use a database of images from an American AI company from which they draw their comparisons from. 
  - **Benefits:** 
     - In theory, the technology is supposed to assist in apprehending criminals across international borders.  When the image of the subject is entered into the system, it is automatically encoded and compared to the already stored profiles, which would contribute to the development of a global facial database. 
  - **Limitations:**
    -  Almost always there is a manual process carried out to verify the results of the automated system which brings up questions about the necessity and efficacy of such a system.  
    -  Furthermore, a program like this is likely coded with the biases of WASP individuals and holds those biases which likely means that Arabic and Asian names/faces are probably more targeted. 

- **[Cooler Screens](https://www.coolerscreens.com/)**
  - **Creator:** Arsen Avakian
  - **Problem:** enhance shopping experience in brick and mortar retail.
  - **Proposed Solutions:** Cooler Screens is a company that utilizes facial recognition advertisements. With cameras and sensors embedded on the doors of refrigerated aisle sections, it allows for companies like Walgreens to advertise to their customers by recognizing factors like age and gender and displaying ads accordingly. These doors allow real time analytics by noting which items customers looked at or picked up, and they shift what products are viewed based on what they think the customer will want to see.
  - **Benefits:** tailored shopping experience, 
  - **Limitations:** Cooler Screens makes assumptions about you based on clothing and appearance. What if your interests don't align with those of the people who dress like you? What if you don't consent to being surveilled while you're shopping?
  - **More Information:** https://retailwire.com/discussion/walgreens-tests-tech-that-sort-of-recognizes-you-in-store/
